[general]
task_name = globe_cbow
device = cpu
seed = 42
num_epoch = 5

[optimization]
learning_rate = 5e-5
batch_size = 32
weight_decay = 0.1

[dataset]
dataset_name = google-news
data_dir = sample-location
shuffle = false
cache_dir = cache-location
train_test_split = 0.2

[model]
embedding_dim = 64
window_size = 4

[tools]
tokenizer = nltk
min_freq = sample-freq
